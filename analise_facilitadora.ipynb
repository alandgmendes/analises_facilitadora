{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN4qUH8GuUdZ/c03xTDLQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alandgmendes/analises_facilitadora/blob/main/analise_facilitadora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de dados da Facilitadora Cultural referente a projetos da Lei Paulo Gustavo\n",
        "\n",
        "Essa análise inicial visa discutir o agregado dos projetos onde a facilitadora teve participação e suas planilhas orçamentárias"
      ],
      "metadata": {
        "id": "7TpiLZdPsnBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente vamos importar as bibliotecas necessárias"
      ],
      "metadata": {
        "id": "RDwiWBVss_4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "from zipfile import ZipFile\n",
        "import locale\n",
        "import re"
      ],
      "metadata": {
        "id": "f3VSvED0smcB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente vamos estudar a planilha 'Controle de Projetos LPG - Facilitadora Cultural\n",
        "'"
      ],
      "metadata": {
        "id": "54pqhQ1ht2r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def format_brazilian_currency(value):\n",
        "    # Format the value as currency with commas as cent separator and dots as milliard separator\n",
        "    formatted_value = '{:,.2f}'.format(value)\n",
        "\n",
        "    # Replace default separators with Brazilian style\n",
        "    formatted_value = formatted_value.replace(',', 'X').replace('.', ',').replace('X', '.')\n",
        "\n",
        "    # Add 'R$ ' before the value\n",
        "    formatted_value = 'R$ ' + formatted_value\n",
        "\n",
        "    return formatted_value\n",
        "\n",
        "# Actual path to your Excel file\n",
        "excel_file_path = 'Controle de Projetos LPG - Facilitadora Cultural.xlsx'\n",
        "\n",
        "# Specify the range of rows and columns you want to select\n",
        "start_row = 1  # Start from row 2 (assuming header is in the first row)\n",
        "end_row = 21   # End at row 22\n",
        "columns_to_select = ['Projeto', 'Gênero', 'Proponente', 'Cidade', 'Nível de Envolvimento', 'Status', 'Edital', 'Valor', 'Link']  # Replace with your column names\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(excel_file_path, header=0)  # Assuming the header is in the first row\n",
        "\n",
        "# Select the desired range of rows and columns\n",
        "selected_data = df.loc[start_row-1:end_row-1, columns_to_select]\n",
        "df = selected_data\n",
        "# Print the selected data\n",
        "print('Todos os projetos:')\n",
        "\n",
        "# Filter the DataFrame by 'Status' equal to 'CANCELADO'\n",
        "df_cancelado = df[df['Status'] == 'CANCELADO']\n",
        "df_n_selec = df[df['Status'] == 'NÃO SELECIONADO']\n",
        "df_aprovados = df[df['Status'] == 'APROVADO']\n",
        "\n",
        "print('Cancelados:')\n",
        "print(df_cancelado['Projeto'])\n",
        "\n",
        "print('Não selecionados:')\n",
        "print(df_n_selec['Projeto'])\n",
        "\n",
        "print('Selecionados:')\n",
        "print(df_aprovados['Projeto'])\n",
        "\n",
        "# Calculate the sum, average, and median of the 'Valor' column\n",
        "valor_sum = df_aprovados['Valor'].sum()\n",
        "valor_avg = df_aprovados['Valor'].mean()\n",
        "valor_median = df_aprovados['Valor'].median()\n",
        "\n",
        "\n",
        "# Print the formatted results\n",
        "print(\"Valor total:\", format_brazilian_currency(valor_sum))\n",
        "print(\"Valor médio por projeto:\", format_brazilian_currency(valor_avg))\n",
        "print(\"Valor mediano:\", format_brazilian_currency(valor_median))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "u9raxxuUtzqw",
        "outputId": "3ce72eeb-21cd-4eb9-d06a-bbfcc66feda2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9a141c45f7a2>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Read the Excel file into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming the header is in the first row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Select the desired range of rows and columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Controle de Projetos LPG - Facilitadora Cultural.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre os cancelados temos:"
      ],
      "metadata": {
        "id": "iuc6i8wOvkJU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmLd7uAKsSKU"
      },
      "outputs": [],
      "source": [
        "valor_sum = df_cancelado['Valor'].sum()\n",
        "formatted_valor_sum = f\"Total Cancelado: R$ {format_brazilian_currency(valor_sum)}\"\n",
        "print(formatted_valor_sum)\n",
        "\n",
        "# Print valor values in the 'Gênero' column\n",
        "genero_values = df_cancelado['Gênero'].unique()\n",
        "print(\"\\nGênero dos cancelados:\")\n",
        "print(genero_values)\n",
        "\n",
        "# Print unique values in the 'Edital' column\n",
        "edital_values = df_cancelado['Edital'].unique()\n",
        "print(\"\\nEditais dos cancelados:\")\n",
        "print(edital_values)\n",
        "\n",
        "# Print unique values in the 'Projeto' column\n",
        "edital_values = df_cancelado['Projeto'].unique()\n",
        "print(\"\\nNomes dos cancelados:\")\n",
        "print(edital_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre os não-selecionados:"
      ],
      "metadata": {
        "id": "EXGIrcnCKhi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valor_sum = df_n_selec['Valor'].sum()\n",
        "formatted_valor_sum = f\"Total não-selecionados: R$ {format_brazilian_currency(valor_sum)}\"\n",
        "print(formatted_valor_sum)\n",
        "\n",
        "# Print valor values in the 'Gênero' column\n",
        "genero_values = df_n_selec['Gênero'].unique()\n",
        "print(\"\\nGênero dos não-selecionados:\")\n",
        "print(genero_values)\n",
        "\n",
        "# Print unique values in the 'Edital' column\n",
        "edital_values = df_n_selec['Edital'].unique()\n",
        "print(\"\\nEditais dos não-selecionados:\")\n",
        "print(edital_values)\n",
        "\n",
        "# Print unique values in the 'Projeto' column\n",
        "edital_values = df_n_selec['Projeto'].unique()\n",
        "print(\"\\nNomes dos não-selecionados:\")\n",
        "print(edital_values)"
      ],
      "metadata": {
        "id": "ig_jMIYPKhHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobre os Selecionados\n",
        "\n"
      ],
      "metadata": {
        "id": "K9jNCrhLw_Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valor_sum = df_aprovados['Valor'].sum()\n",
        "formatted_valor_sum = f\"Total selecionados: R$ {format_brazilian_currency(valor_sum)}\"\n",
        "print(formatted_valor_sum)\n",
        "print('\\n\\n\\n')\n",
        "# Print valor values in the 'Gênero' column\n",
        "genero_values = df_aprovados['Gênero'].unique()\n",
        "print(\"\\nGênero dos selecionados:\\n\\n\")\n",
        "for generoItem in genero_values:\n",
        "  print(generoItem)\n",
        "print('\\n\\n\\n')\n",
        "# Print unique values in the 'Edital' column\n",
        "edital_values = df_aprovados['Edital'].unique()\n",
        "print(\"\\nEditais dos selecionados:\\n\\n\")\n",
        "for edital in edital_values:\n",
        "  print(edital)\n",
        "print('\\n\\n\\n')\n",
        "# Print unique values in the 'Projeto' column\n",
        "nomes_projeto = df_aprovados['Projeto'].unique()\n",
        "print(\"\\nNomes dos selecionados:\\n\\n\")\n",
        "for projeto in nomes_projeto:\n",
        "  print(projeto)"
      ],
      "metadata": {
        "id": "DhNyLVFTM5H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Projeto' is the column containing project names, and 'Valor' is the column with values\n",
        "# Replace these with your actual column names\n",
        "projects = df_aprovados['Projeto']\n",
        "values = df_aprovados['Valor']\n",
        "\n",
        "# Calculate median and average\n",
        "valor_median = values.median()\n",
        "valor_avg = values.mean()\n",
        "\n",
        "# Plot a bar chart of 'Valor' for each 'Projeto'\n",
        "plt.figure(figsize=(10, 6))\n",
        "projeto_sum = df_aprovados.groupby('Projeto')['Valor'].sum().sort_values()\n",
        "projeto_sum.plot(kind='barh', color='skyblue')\n",
        "\n",
        "# Add lines for median and average\n",
        "plt.axvline(valor_median, color='red', linestyle='--', label='Mediana')\n",
        "plt.axvline(valor_avg, color='green', linestyle='--', label='Média')\n",
        "\n",
        "\n",
        "plt.title('Projetos e valores')\n",
        "plt.xlabel('Valor')\n",
        "plt.ylabel('Projeto')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E8oXwmQ7xOmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum 'Valor' by 'Gênero'\n",
        "genero_sum = df_aprovados.groupby('Gênero')['Valor'].sum().sort_values()\n",
        "genero_count = df_aprovados['Gênero'].value_counts().loc[genero_sum.index]  # Count of items in each 'Gênero'\n",
        "\n",
        "# Create a bar chart for each 'Gênero'\n",
        "plt.figure(figsize=(10, 6))\n",
        "genero_sum.plot(kind='barh', color='skyblue', label='Valor')\n",
        "\n",
        "\n",
        "# Display count of items in the legend\n",
        "for genero, count in genero_count.items():\n",
        "    plt.text(0, genero_sum.index.get_loc(genero), f'({count})', va='center', ha='left', color='black')\n",
        "\n",
        "plt.title('Valor e número de itens por Gênero')\n",
        "plt.xlabel('Valor')\n",
        "plt.ylabel('Gênero')\n",
        "plt.legend(loc='lower right')  # Set the legend to the bottom right\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OrKpc4LYxhW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum 'Valor' by 'Nível de Envolvimento'\n",
        "nivel_sum = df_aprovados.groupby('Nível de Envolvimento')['Valor'].sum().sort_values()\n",
        "nivel_count = df_aprovados['Nível de Envolvimento'].value_counts().loc[nivel_sum.index]  # Count of items in each 'Nível de Envolvimento'\n",
        "\n",
        "# Create a bar chart for each 'Nível de Envolvimento'\n",
        "plt.figure(figsize=(10, 6))\n",
        "nivel_sum.plot(kind='barh', color='skyblue', label='Valor')\n",
        "\n",
        "# Display count of items in the legend\n",
        "for nivel, count in nivel_count.items():\n",
        "    plt.text(0, nivel_sum.index.get_loc(nivel), f'({count})', va='center', ha='left', color='black')\n",
        "\n",
        "plt.title('Valores de projeto e Nível de Envolvimento')\n",
        "plt.xlabel('Valor')\n",
        "plt.ylabel('Nível de Envolvimento')\n",
        "plt.legend(loc='lower right')  # Set the legend to the bottom right\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zodKpe34xomU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos agora analisar as planilhas orçamentárias*. Atualmente, o melhor meio para fazer upload delas é colocá-las num arquvio chamado files.zip\n",
        "\n",
        "\n",
        "\n",
        "(Obs: os proetos da categoria Pessoa física não têm planilhas orçamentárias associadas)\n",
        "*O projeto 'Cidade de muitas vozes' está em disputa e não será analisado\n"
      ],
      "metadata": {
        "id": "gs0UHfbtyOen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the zip file\n",
        "zip_file_path = 'files.zip'\n",
        "\n",
        "# Directory to extract the contents of the zip file\n",
        "extracted_dir = 'extracted_data'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extracted_dir, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Get a list of all xlsx files in the extracted directory\n",
        "xlsx_files = [file for file in os.listdir(extracted_dir) if file.endswith('.xlsx')]\n",
        "print(xlsx_files)\n",
        "# Dictionary to store DataFrames for each project\n",
        "dataframes = {}\n",
        "\n",
        "# Iterate through each xlsx file, read into a DataFrame, and store in a dictionary\n",
        "for xlsx_file in xlsx_files:\n",
        "    # Extract project name from the file name\n",
        "    project_name = xlsx_file.split('-')[1].strip().split('.xlsx')[0].strip()\n",
        "\n",
        "    # Read xlsx into a DataFrame\n",
        "    file_path = os.path.join(extracted_dir, xlsx_file)\n",
        "\n",
        "    # Read the file and skip the first 3 rows to get to the 4th row (index 3)\n",
        "    df_temp = pd.read_excel(file_path, skiprows=3)\n",
        "\n",
        "    # Store the DataFrame in the dictionary with the project name as the key\n",
        "    dataframes[project_name] = df_temp\n",
        "\n",
        "# Now, dataframes dictionary contains DataFrames for each project\n",
        "# You can access them like dataframes['Cidade de Muitas Vozes']\n",
        "dataframes_keys = list(dataframes.keys())\n",
        "todos = list(dataframes.keys())\n",
        "aprovados = list(df_aprovados[\"Projeto\"])\n",
        "for item_apr in aprovados:\n",
        "  print(item_apr)"
      ],
      "metadata": {
        "id": "pLfH3vrbxaOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for project_name, df in dataframes.items():\n",
        "    print(f\"DataFrame Name: {project_name}\")\n",
        "    print(\"Columns:\")\n",
        "    for column in df.columns:\n",
        "        print(f\"  - {column}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "U6somiDh28FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisaremos a princípio as colunas comuns a todas as tabelas"
      ],
      "metadata": {
        "id": "q7VXgfafA0xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of universal columns\n",
        "universal_columns = ['Descrição do Item', 'Justificativa', 'Unidade de Medida', 'Valor Unitário', 'Quantidade', 'Valor Total']\n",
        "\n",
        "# Dictionary to store DataFrames for each project with common columns\n",
        "dataframesCommon = {}\n",
        "# Iterate through each project and its corresponding DataFrame\n",
        "for project_name, df in dataframes.items():\n",
        "    # Filter the columns to keep only universal columns\n",
        "    print(project_name)\n",
        "    df = df[universal_columns]\n",
        "\n",
        "    # Update the dataframe in the dictionary\n",
        "    dataframesCommon[project_name] = df\n",
        "\n",
        "    # Print the project name and updated columns\n",
        "    print(f\"Project: {project_name}\")\n",
        "    print(f\"Updated Columns:{df.columns}\")\n",
        "\n",
        "    # Add a blank line for better readability\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "3hzYydelA0ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = dataframesCommon['Quando o Presidente Comeu Minha Mãe']\n",
        "def generate_project_charts(df, project_name):\n",
        "    df = df.iloc[:-1].copy()\n",
        "\n",
        "    # Drop rows where 'Unidade de Medida' is NaN\n",
        "    df = df.dropna(subset=['Unidade de Medida'])\n",
        "\n",
        "    # Replace all words starting with \"servi\" or \"Servi\" with \"Serviços\", ignoring NaN values\n",
        "    for index, row in df.iterrows():\n",
        "        if pd.notna(row['Unidade de Medida']) and row['Unidade de Medida'].lower().startswith('servi'):\n",
        "            df.loc[index, 'Unidade de Medida'] = 'Serviços'\n",
        "\n",
        "    # Calculate the total value of each item\n",
        "    df['Valor Total'] = df['Valor Unitário'] * df['Quantidade']\n",
        "\n",
        "    # Calculate the total value of each unit of measure\n",
        "    df_unit_values = df.groupby('Unidade de Medida')['Valor Total'].sum()\n",
        "\n",
        "    # Sort the DataFrame by values in descending order\n",
        "    df_unit_values = df_unit_values.sort_values(ascending=False)\n",
        "\n",
        "    # Calculate the count of units of measure equal to \"serviço\"\n",
        "    count_service = df[pd.notna(df['Unidade de Medida']) & df['Unidade de Medida'].str.lower().str.contains('servi[çc]o', na=False)]['Unidade de Medida'].count()\n",
        "\n",
        "    count_people = df[pd.notna(df['Unidade de Medida']) & df['Unidade de Medida'].str.lower().str.contains('servi[çc]o', na=False)]['Quantidade'].sum()\n",
        "\n",
        "    # Calculate the mean, median, and total value of \"serviço\"\n",
        "    service_values = df[pd.notna(df['Unidade de Medida']) & df['Unidade de Medida'].str.lower().str.contains('serviços')]['Valor Total']\n",
        "    mean_service = service_values.mean()\n",
        "    median_service = service_values.median()\n",
        "    total_service = service_values.sum()\n",
        "\n",
        "    # Calculate the overall total\n",
        "    overall_total = df['Valor Total'].sum()\n",
        "\n",
        "    # Plot the bar chart\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.bar(df_unit_values.index, df_unit_values.values)\n",
        "\n",
        "    # Rotate x-axis labels by 45 degrees\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    plt.title(f'Gráfico de barras de unidades de medida para o projeto {project_name}')\n",
        "    plt.ylabel('Valor total')\n",
        "\n",
        "    # Add information below the graph with left alignment and larger font size\n",
        "    plt.text(0.0, -0.55, f'Projeto: {project_name}\\n'\n",
        "                          f'Quantidade de itens \"serviços\": {count_service}\\n'\n",
        "                          f'Quantidade de pessoas envolvidas: {count_people}\\n'\n",
        "                          f'Média do valor de serviço item: {format_brazilian_currency(mean_service)}\\n'\n",
        "                          f'Mediana: {format_brazilian_currency(median_service)}\\n'\n",
        "                          f'Valor total de serviços: {format_brazilian_currency(total_service)}\\n'\n",
        "                          f'Total Geral: {format_brazilian_currency(overall_total)}',\n",
        "             horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes,\n",
        "             color='black', fontsize=14)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example\n",
        "test.name = 'Quando o Presidente Comeu Minha Mãe'\n",
        "generate_project_charts(test, test.name)"
      ],
      "metadata": {
        "id": "mgaeHVMVPyr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionar visualização de acessibilidade\n"
      ],
      "metadata": {
        "id": "M6Nv_662m_UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming dataframesCommon is a dictionary of dataframes\n",
        "all_dataframes = list(dataframesCommon.values())\n",
        "\n",
        "# Concatenate all dataframes vertically\n",
        "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "\n",
        "# Now you can perform the analysis on the combined dataframe\n",
        "generate_project_charts(combined_df, \"Total dos projetos\")"
      ],
      "metadata": {
        "id": "m9RtcMLPqElp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calcular ROI\n",
        "calcular o ROIS\n",
        "Efeito multiplicador do recurso\n",
        "individual por projeto e agregado\n"
      ],
      "metadata": {
        "id": "uggHH-r4DXww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vagas por segmento nos aprovados\n",
        "valor total dos recursos por segmento nos aprovados\n",
        "valor médio do salário por segmento\n",
        "valor total pra acessibilidade do agregado de projetos e de cada projeto individual"
      ],
      "metadata": {
        "id": "ojSkYUAPZbYK"
      }
    }
  ]
}